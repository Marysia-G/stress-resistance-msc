{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Data Import\n",
    "\n",
    "Welcome in the workflow of analyzing growth data for Y. lipolytica Transcription Factors strains :)\n",
    "\n",
    "The script is developed so that you can skip most of the parts and input as little as possible by yourself.\n",
    "The code parts are all described with a # sign at the beginning of each python code cell - you don't need to change anything in them, just run them.\n",
    "The parts of the code that needs Your involvement are subseeded with a markdown cell (such as this one) - which appear as a plain text. In each of such markdown cells Your task in the subsequent code will be explained.\n",
    "\n",
    "Have fun watching Your data being analyzed ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform all the necessary imports of libraries\n",
    "\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file you are only asked to insert the dilution factor for your OD600 values.\n",
    "\n",
    "It is valid only if you used the same dilution factor throughout the whole experiment (with all conditions and timepoints). However if you diluted the cells differently through the course of your experiments, you have to enter a value of 1 in the below cell, and calculate the actual growth in your input files.\n",
    "\n",
    "Meaning:\n",
    "- if the dilutions are consistent you can input raw absorbance data, \n",
    "- if the dilutions change you have to calculate the growth yourself and use it as input files, and enter 1 as the dilution factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using dilution factor: 1.0\n"
     ]
    }
   ],
   "source": [
    "dilution_factor = float(os.environ.get(\"DILUTION_FACTOR\", 1.0))  # 1.0 is the default\n",
    "print(f\"Using dilution factor: {dilution_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign ECY numbers used in the experiments to a list of names\n",
    "# To change anything in the following three cells you have to keep the order the same \n",
    "# in ECY numbers, corresponding TF name and type of modification\n",
    "\n",
    "numbers_ECY = '''\n",
    "352\n",
    "353\n",
    "354\n",
    "642\n",
    "643\n",
    "644\n",
    "645\n",
    "646\n",
    "647\n",
    "648\n",
    "649\n",
    "651\n",
    "652\n",
    "653\n",
    "654\n",
    "655\n",
    "656\n",
    "657\n",
    "658\n",
    "659\n",
    "660\n",
    "661\n",
    "662\n",
    "663\n",
    "664\n",
    "665\n",
    "666\n",
    "667\n",
    "668\n",
    "995\n",
    "996\n",
    "997\n",
    "998\n",
    "999\n",
    "1000\n",
    "1001\n",
    "1002\n",
    "1005\n",
    "1006\n",
    "1007\n",
    "1016\n",
    "1017\n",
    "1018\n",
    "1039\n",
    "1040\n",
    "1041\n",
    "1042\n",
    "1043\n",
    "1044\n",
    "1045\n",
    "1049\n",
    "1050\n",
    "1051\n",
    "F6\n",
    "A3\n",
    "A5\n",
    "C6\n",
    "G5\n",
    "H5\n",
    "A11\n",
    "B10\n",
    "B12\n",
    "'''\n",
    "list_ECY = [f\"{item.strip()}\" for item in numbers_ECY.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign TFs names used in the experiments to a list of names\n",
    "\n",
    "names_TFs = '''\n",
    "control\n",
    "control\n",
    "control\n",
    "TF011\n",
    "TF011\n",
    "TF011\n",
    "Mhy1\n",
    "Mhy1\n",
    "Mhy1\n",
    "Hap1\n",
    "Hap1\n",
    "TF036\n",
    "TF036\n",
    "TF036\n",
    "Dal81\n",
    "Dal81\n",
    "Dal81\n",
    "Yas1\n",
    "Yas1\n",
    "Yas1\n",
    "Msn4w\n",
    "Msn4w\n",
    "Msn4w\n",
    "Msn4m\n",
    "Msn4m\n",
    "Msn4m\n",
    "Msn4b\n",
    "Msn4b\n",
    "Msn4b\n",
    "Hap1\n",
    "Hap1\n",
    "Dal81\n",
    "Dal81\n",
    "Dal81\n",
    "Yas1\n",
    "Yas1\n",
    "Yas1\n",
    "Msn4\n",
    "Msn4\n",
    "Msn4\n",
    "TF009\n",
    "TF009\n",
    "TF009\n",
    "Mhy1\n",
    "Mhy1\n",
    "Mhy1\n",
    "TF011\n",
    "TF011\n",
    "TF011\n",
    "TF009\n",
    "TF036\n",
    "TF036\n",
    "TF036\n",
    "control_prot\n",
    "TF009\n",
    "TF011\n",
    "TF036\n",
    "Yas1\n",
    "Mhy1\n",
    "Msn4\n",
    "Dal81\n",
    "Hap1\n",
    "'''\n",
    "\n",
    "list_TFs = [f\"{item.strip()}\" for item in names_TFs.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign modifications names used in the experiments to a list of names\n",
    "\n",
    "names_Modifications = '''\n",
    "control\n",
    "control\n",
    "control\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "OE\n",
    "OE\n",
    "OE\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "KO\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "OE_prot\n",
    "'''\n",
    "\n",
    "list_Modifications = [f\"{item.strip()}\" for item in names_Modifications.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for each ECY number to the corresponding name of TF and type of modification\n",
    "\n",
    "dictionaryTFs = dict(zip(list_ECY, list_TFs))\n",
    "dictionaryModifications = dict(zip(list_ECY, list_Modifications))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test_2.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test2_2.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test2_1.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test3_1.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test3_3.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test_3.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test_1.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test3_2.xlsx', '\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\results_test2_3.xlsx']\n",
      "['\\\\\\\\wsl.localhost\\\\Ubuntu\\\\home\\\\marysia\\\\stress_resistance_msc\\\\data\\\\test_strain_layout.xlsx']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "results = [f for f in glob.glob(os.path.join(DATA_PATH, \"results*.xlsx\")) if not \":\" in f]\n",
    "print(\"Found files:\", results)\n",
    "if not results:\n",
    "    print(\"No Excel files found in /app/data. Please upload files and re-run.\")\n",
    "    \n",
    "strain_layout_upload = glob.glob(os.path.join(DATA_PATH, '*strain_layout.xlsx'))\n",
    "if not strain_layout_upload:\n",
    "    print('No strain layout template found in /app/data. Please upload file and re-run.')\n",
    "print(strain_layout_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_data = []\n",
    "\n",
    "for file in results:\n",
    "    \n",
    "    # Load and process condition and time data from an excel filename\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    parts = filename.split('_')\n",
    "\n",
    "    if len(parts) >= 3:\n",
    "        condition = parts[1]\n",
    "        time = parts[2]\n",
    "    else:\n",
    "        condition = 'Unknown'\n",
    "        time = 'Unknown'\n",
    "        \n",
    "    # Load and process strain layout data\n",
    "    strain_layout = pd.read_excel(strain_layout_upload[0], header=None)\n",
    "    strain_layout = pd.melt(strain_layout, id_vars=None, value_name='ECY_number').dropna()\n",
    "\n",
    "    # Load and process OD data\n",
    "    od_results = pd.read_excel(file, header=None)  # use the current file from loop\n",
    "    od_results = pd.melt(od_results, id_vars=None, value_name='absorbance_600').dropna()\n",
    "\n",
    "    # Combine into one DataFrame\n",
    "    data = pd.DataFrame({\n",
    "        'ECY_number': strain_layout['ECY_number'],\n",
    "        'absorbance_600': od_results['absorbance_600']\n",
    "    })\n",
    "\n",
    "    # Clean up and annotate\n",
    "    data['ECY_number'] = data['ECY_number'].astype(str).str.split('.').str[0]\n",
    "    data['absorbance_600'] = data['absorbance_600'].astype(float)\n",
    "    data['TF'] = data['ECY_number'].map(dictionaryTFs).fillna('Unknown')\n",
    "    data['modification'] = data['ECY_number'].map(dictionaryModifications).fillna('Unknown')\n",
    "    data['growth'] = data['absorbance_600'] * dilution_factor\n",
    "    data['condition'] = condition\n",
    "    data['time'] = time\n",
    "    data['time'] = data['time'].astype(int)\n",
    "    data['strain_name'] = data['TF'] + '_' + data['modification']\n",
    "    data['variant_column'] = data['strain_name'] + '_' + data['condition'] + '_' + data['time'].astype(str)\n",
    "    \n",
    "    # Append current dataframe to a list of data\n",
    "    list_of_data.append(data)\n",
    "    \n",
    "# Update a dataframe with all results from experiments performed to date\n",
    "all_data = pd.concat(list_of_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export excelfile with current date\n",
    "\n",
    "OUTPUT_PATH = os.path.join(os.getcwd(), \"output_data\")\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "output_filename = f\"{current_date}_growth_data.xlsx\"\n",
    "output_path = os.path.join(OUTPUT_PATH, output_filename)\n",
    "all_data.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
